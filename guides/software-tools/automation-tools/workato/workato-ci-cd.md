# Workato Workflow Components and Data Structures

Workato is a low-code integration platform that uses **recipes** (automated workflows) to connect applications. Each recipe consists of a **trigger** event and a sequence of **actions**, allowing data to flow between systems. Key components of Workato integrations include recipes, connections, custom connectors, lookup tables, and variables. Below is a breakdown of each component and how they are structured internally, with an emphasis on using Excel and HTTP for loan processing integrations.

## Recipes (Workflows)

**Recipes** are the core workflows in Workato. A recipe defines a trigger (the event that starts the workflow) and a series of action steps to execute. Triggers can be time-based (scheduler), data-based (e.g. a new row in a spreadsheet), or event-based (webhooks). Actions perform tasks like reading/writing data, sending HTTP requests, or conditional logic. Internally, every recipe is represented in JSON format – when you export a recipe, Workato produces a JSON file describing the trigger and each action step ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=You%20can%20export%20packages%20to,You%20can%20use%20packages%20to)). For example, the recipe JSON includes fields for the connector used (`provider`), the specific action/trigger name, input parameters, and nested **blocks** for sequences or branches of actions ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=,n)) ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=immediately.%20,4a99ae5d25ae%5C%22%7D%22%2C%20%22config%22%3A%22%5B%7B%5C%22keyword%5C%22%3A%5C%22application%5C%22%2C%5C%22name%5C%22%3A%5C%22clock)). Each step in the JSON has a unique identifier and may contain sub-steps (for loops or conditional branches) in nested arrays. This structured data model allows Workato to recreate the recipe exactly when imported.

*Key features of recipes:*

- **Trigger:** Defines the event that starts the recipe (e.g. “New row in Excel worksheet” or a scheduled time). The trigger is always step number 0 in the recipe’s JSON code and includes any input settings (like polling interval or file location) ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=,Trigger)).
- **Actions:** Each subsequent step performs an action using a connector (e.g. read Excel data, call an HTTP API). Actions are sequential by default, and can include conditional actions (if/else), loops (e.g. **For each**), or error handling blocks. In the JSON representation, actions appear as objects with their connector `provider` (app), action `name`, input parameters, and a `uuid` for reference ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=immediately.%20,4a99ae5d25ae%5C%22%7D%22%2C%20%22config%22%3A%22%5B%7B%5C%22keyword%5C%22%3A%5C%22application%5C%22%2C%5C%22name%5C%22%3A%5C%22clock)).
- **Data pills:** As actions run, they output data in the form of **datapills** – these are typed data fields (e.g. text, number, date) representing outputs of triggers or actions. Datapills from one step can be mapped into inputs of subsequent steps, forming a data pipeline. For instance, an Excel trigger’s output pills (columns from a new row) can be mapped into an HTTP action’s request body.
- **Recipe logic:** Recipes can include complex logic flows. Under the hood, the JSON `block` structure nests actions inside triggers and conditional branches, reflecting the hierarchy of the workflow. This means a **For each** loop or an **If** condition will appear as a nested block of actions in the recipe’s JSON definition.

**Data structures in Excel-to-Loan example:** Consider a recipe that processes loan applications from an Excel file and sends them to a loan system via HTTP. The recipe’s trigger might be **“New file in folder”** (if Excel file upload triggers the process) or a scheduled trigger that checks an Excel sheet. Action steps would include using the Excel connector to read the spreadsheet’s rows, then for each row, an HTTP connector action to send the data to a loan processing API. In this recipe, the Excel connector provides output datapills for each column in the row (e.g. loan applicant name, amount, etc.), which are mapped into the HTTP request JSON payload. Workato automatically parses Excel data into structured output – for example, the **Get cells from range** action in the Excel connector lets you define column names and returns each row’s data as labeled datapills for easy mapping ([Get rows from Excel sheet whenever a new Excel file is created via API | by Isabelle Leong | Medium](https://medium.com/@isabelle_leong/get-rows-from-excel-sheet-whenever-a-new-excel-file-is-created-via-api-1f6566494549#:~:text=API%20endpoint%20that%20we%20are,calling%20with%20formula%20mode%20enabled)). The HTTP action then uses those datapills in its request body. The entire flow – trigger, Excel read, HTTP POST – is encapsulated in the recipe JSON so it can be exported or versioned as code.

## Connections

**Connections** in Workato represent the authenticated link to an external application or service. Each recipe step that interacts with an app (e.g. Excel or an HTTP API) uses a connection to handle authentication and endpoint details. A connection includes non-sensitive metadata like the application type and a user-defined name, and securely stores credentials or tokens required for access. Workato supports various auth methods, from OAuth2 to API keys; for example, the HTTP connector supports auth types including **None, Basic, Header auth, Query params, OAuth2, and more** ([Workato connectors - HTTP - Connection setup | Workato Docs](https://docs.workato.com/developing-connectors/http/connection-setup.html#:~:text=The%20steps%20required%20to%20create,supports%20the%20following%20authentication%20types)), and the Excel connector uses OAuth2 to connect to Microsoft’s Graph API for OneDrive/SharePoint access ([Workato connectors - Excel | Workato Docs](https://docs.workato.com/connectors/excel.html#:~:text=Microsoft%20Excel%20,data%20visualization%20and%20analysis%20tool)).

Internally, connections are not fully exported for security. When you export a recipe or package, **credentials and secrets are omitted** for safety ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=For%20security%20reasons%2C%20exporting%20a,placeholder%20is%20required%20after%20import)). The exported package will contain only a placeholder with the connection’s name, app type, and possibly some configuration, but no passwords or tokens ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=For%20security%20reasons%2C%20exporting%20a,placeholder%20is%20required%20after%20import)). On import, Workato attempts to match these placeholders with existing connections in the target workspace. If a connection of the same app type and name already exists (and there is only one such connection), Workato will automatically map the recipe to use that existing connection ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=When%20importing%20a%20package%2C%20Workato,by%20the%20recipes%20after%20import)). This way, you can maintain different credentials in dev/test/prod environments – e.g. a “Loan API” connection in dev might point to a sandbox endpoint with sandbox credentials, while in prod the recipe maps to a “Loan API” connection with the production URL and credentials. If no matching connection is found, the import will create a placeholder and you’ll need to manually configure or **“reconnect”** it by providing the credentials in the new environment ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=placeholder%20contains%20only%20the%20application,placeholder%20is%20required%20after%20import)).

*Environment-specific practice:* Because connections are environment-specific, one best practice is to use separate Workato workspaces or projects for development, QA, and production, each with its own set of connections ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=One%20of%20the%20main%20advantages,application%20account%20with%20live%20data)). This allows, for example, Excel in dev to connect to a test Office 365 account and the loan HTTP calls to use a test server, while production uses live accounts. The connection placeholders in exported recipes ensure that sensitive details never leave the source environment, and they require re-authentication or mapping to existing connections in the target environment. Workato also offers a **Secrets Management** feature to integrate with external vaults (like AWS Secrets Manager or Azure Key Vault) so that connection credentials can be referenced as dynamic secrets rather than stored in plain form ([Secrets Management For Connection Credentials | Workato Docs](https://docs.workato.com/security/data-protection/secrets-management/secrets-management.html#:~:text=To%20simplify%20the%20management%20of,like%20passwords%20and%20API%20tokens)) ([Secrets Management For Connection Credentials | Workato Docs](https://docs.workato.com/security/data-protection/secrets-management/secrets-management.html#:~:text=With%20a%20secrets%20manager%2C%20you,sensitive%20info%20like%20a%20password)). This means in a CI/CD pipeline, you might store secrets in an external vault and simply ensure each environment’s connections are configured to pull the correct secret – avoiding manual updates and enabling safe credential rotation.

## Custom Connectors

When a needed app does not have a pre-built connector in Workato, you can build a **custom connector** using Workato’s Connector SDK. Custom connectors are essentially code (written in Ruby) that define how to interact with an app’s API – including triggers, actions, request/response schemas, and so on. In Workato, custom connectors appear as just another application you can connect to, but under the hood they are user-defined. They are developed as projects (with Ruby files) using the Workato Connector SDK, and can be managed via the Workato CLI (a Ruby gem provided by Workato). The CLI allows developers to edit connector code locally, run tests, and **push** the custom connector to their Workato workspace for use ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=,your%20Workato%20workspace)) ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=Run%20the%20workato%20push%20command%3A)).

From a data structure perspective, a custom connector’s definition includes metadata (connector name, description, etc.) and the Ruby code for each trigger/action. This code specifies how to make HTTP calls to the target API and how to parse inputs/outputs. When exporting a recipe that depends on a custom connector, the connector itself is treated as a dependent asset. Workato packages can include custom connectors so that they can be imported into another environment. On import, if a connector with the same name already exists, it will be **updated/overwritten**; if not, it will create a new connector in the target account ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Selected%20folder%20Custom%20connectors%20Overwrites,Lookup%20table)). The exported form of a custom connector in the package is a JSON representation of the connector (including its actions/triggers definitions). Once imported, the connector’s code is available in the target environment’s Connector SDK section, where it can be further edited or tested as needed.

**Usage in Excel/Loan scenario:** If the loan processing system had a complex API, one might create a custom connector for it instead of using raw HTTP calls in each recipe. The custom connector could define actions like “Create Loan Application” or “Get Loan Status” with the required input fields and outputs. This abstracts the HTTP details behind a friendly interface. The recipe then simply uses the custom connector’s actions. Under the hood, those actions execute the Ruby-defined requests. In a CI/CD pipeline, the connector’s code would be maintained in source control and deployed via the Workato CLI (e.g. running `workato push` after testing) ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=Run%20the%20workato%20push%20command%3A)), ensuring the custom connector stays in sync across environments.

## Lookup Tables

**Lookup tables** are a feature in Workato that provides a lightweight database or spreadsheet-like table within the platform. They are useful for storing reference data, mappings, or even small amounts of stateful data that recipes can read or update. A lookup table is defined by a name and a set of columns (schema), and it holds rows of data (each row is basically a record with values for those columns). In recipes, you can use lookup table actions to **add rows, update rows, delete rows, or search for rows**. For example, you might have a lookup table to map loan program codes to human-readable descriptions, or a table to log processed Excel row IDs to prevent duplicates.

From an internal data structure standpoint, lookup table data is stored in Workato’s cloud and can be exported as part of a package. **Exporting and importing lookup tables:** The package always includes the table schema (columns) so the table structure can be recreated ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=)). You have the option to include the data as well – when creating an export manifest, you can choose to include table data. During import, Workato will ask if you want to **“Import data” or “Ignore data”** for each lookup table ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Lookup%20tables%20in%20the%20zip,be%20or%20overwritten%20or%20ignored)) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=%E2%80%98Overwrite%E2%80%99%20will%20cause%20all%20table,table%20was%20exported%20with%20data)). This is important for environment promotion: sometimes you want to carry over reference data, but other times the target environment should maintain its own data. If you choose to import the data, the table in the target will be overwritten with the data from the package (replacing existing rows); if you ignore it, the table’s schema will come over but its rows will remain untouched in the target environment ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=%E2%80%98Overwrite%E2%80%99%20will%20cause%20all%20table,table%20was%20exported%20with%20data)). By default, Workato recommends including data in the export and using “overwrite” on import, unless there’s a reason to preserve target-specific data ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Workato%20recommends%20you%20establish%20rules,of%20the%20package%20being%20imported)).

**Using lookup tables for persistent state:** Lookup tables can also serve as a way to maintain state across recipe jobs. Recall that normal recipe variables reset each run – a lookup table can act as a **persistent store**. For instance, in an Excel integration, if your recipe runs daily to process new rows, you could use a lookup table to keep track of the last processed row or file timestamp. Each run, the recipe can look up the last processed ID from the table, and update it at the end of the run. This effectively creates a persistent variable. In fact, Workato experts have suggested using a dedicated “Global Variables” lookup table for values that need to persist across jobs, since **the native Variables are job-scoped only** ([Persistent Variables in Workato with a Global Variables Lookup Table](https://jasonraisleger.com/workato/persistent-variables-in-workato-with-a-global-variables-lookup-table.html#:~:text=In%20Workato%20recipes%2C%20there%20is,variable%20values%20across%20job%20iterations)). By designing a table with columns for variable names and values, recipes can read and update those to maintain continuity between runs.

Lookup tables are limited in size (they are meant for small to moderate amounts of data, not as a full database). But they are extremely handy for quick data mappings (like translating codes or aggregating results) within a recipe, because they can be accessed with zero external calls. They also do not consume tasks when reading data via the lookup, since it’s an internal operation.

## Variables

Workato **Variables** (the “Variables” app/tool by Workato) allow recipes to store and update values during the execution of a job. Unlike datapills which are outputs of steps, a variable is explicitly created by the user as a container for data that might change or be referenced multiple times in the recipe. For example, you might create a variable to accumulate a total, or to hold a value that you need to refer to in multiple steps. Variables are *mutable* and user-declared ([Variables by Workato | Workato Docs](https://docs.workato.com/features/variables.html#:~:text=Workato%20variable%20is%20a%20user,be%20changed%20within%20a%20recipe)), meaning you can change their value as the recipe runs (something you cannot do with a static datapill output).

Important characteristics of Workato variables:

- **Scope and lifetime:** Variables exist only within a single job execution. When a recipe job starts, any variables it creates are initialized (you can set default values), and they live through that job’s steps. Once the job completes, the variables are gone. They do **not persist across separate trigger events** ([Variables by Workato | Workato Docs](https://docs.workato.com/features/variables.html#:~:text=The%20lifetime%20of%20a%20variable,access%20this%20across%20different%20jobs)). This is why they are often used for calculations or temporary flags within one run.
- **Data types:** When you create a variable (using the **“Create variable”** action from the **Variables by Workato** connector), you must specify a data type (string, integer, list, etc.) ([Variables by Workato | Workato Docs](https://docs.workato.com/features/variables.html#:~:text=Workato%20variables%20are%20typed,variable%2C%20use%20update%20variables%20action)) ([Variables by Workato | Workato Docs](https://docs.workato.com/features/variables.html#:~:text=This%20action%20creates%20variables%20in,string)). This typing helps ensure you store the right kind of value and can perform type-appropriate operations. For instance, a variable declared as integer can be incremented by arithmetic in an **Update variable** step.
- **Usage:** To use variables in a recipe, you add the **Create variables** action at some point (often at the start of the recipe) to declare one or more variables. Thereafter, use **Update variables** actions to change their values as needed. The current value of a variable is available as a datapill (under a special “Variables” data tree) that can be mapped into other actions just like any output.
- **No automatic persistence:** Because variables reset each job, if you need to preserve values between runs (for example, remembering a last processed record ID or an accumulated total), you must use another mechanism. Common approaches are using lookup tables or Workato’s **properties** (described below) as a form of global variable. As an example, a community guide shows how to maintain **persistent variables** by writing them to a “Global Variables” lookup table at the end of each run and reading from it at the start of the next run ([Persistent Variables in Workato with a Global Variables Lookup Table](https://jasonraisleger.com/workato/persistent-variables-in-workato-with-a-global-variables-lookup-table.html#:~:text=I%20created%20a%20dedicated%20lookup,columns%20depending%20on%20your%20needs)) ([Persistent Variables in Workato with a Global Variables Lookup Table](https://jasonraisleger.com/workato/persistent-variables-in-workato-with-a-global-variables-lookup-table.html#:~:text=This%20method%20enables%20the%20use,robustness%20of%20your%20Workato%20recipes)).

In our Excel to loan system scenario, variables might be used to hold intermediate data while processing each row. For instance, you could use a variable to count how many loan records were successfully sent, or to accumulate an error message string to email later. These would be created at the start of the job and updated inside the row processing loop. Once the recipe finishes, you could, say, log the count or send an email using the final value of those variables. If there’s a need to remember something for the next run (say, the last row number processed in the Excel sheet), you wouldn’t rely on a variable (since it will reset); instead you might store that in a lookup table or an **environment property**.

## Exporting and Importing Workato Packages (Lifecycle Management)

Workato provides **Recipe Lifecycle Management (RLCM)** features to promote integrations from development to testing and production. The main mechanism is through **packages** – these are zip files that bundle recipes and their dependent assets (connections, connectors, lookup tables, etc.) in a portable format. Understanding the mechanics of export/import is key to implementing CI/CD and version control for Workato.

### Exporting Packages (Manifest and Structure)

To export a set of recipes, you create an **export manifest** in Workato. The manifest is essentially a list of all assets you want to include in the package ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=)). This typically involves selecting one or more recipe folders (e.g. a project folder) and letting Workato auto-include all recipes inside and any dependencies those recipes have. You can also fine-tune the manifest by including/excluding specific dependencies. For example, you may choose to include certain lookup tables or exclude others. Once the manifest is defined, Workato generates the package as a `.zip` file containing a **JSON file for each asset** ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=You%20can%20export%20packages%20to,You%20can%20use%20packages%20to)). Each recipe becomes a `<recipe_name>.recipe.json` file, each connection a `.connection.json` file, etc. (Workato auto-generates file names if not specified, typically using an `asset_<index>.<type>.json` scheme) ([Workato API - Recipe Lifecycle Management | Workato Docs](https://docs.workato.com/workato-api/recipe-lifecycle-management.html#:~:text=optional%20Whether%20the%20asset%20is,Defaults%20to%20the%20root%20folder)) ([Workato API - Recipe Lifecycle Management | Workato Docs](https://docs.workato.com/workato-api/recipe-lifecycle-management.html#:~:text=optional%20Name%20in%20the%20exported,Defaults%20to%20the%20root%20folder)).

**What’s inside the package:** The zip file is a collection of JSON definitions. For instance, a recipe JSON includes its name, description, the code (as that JSON string of trigger/actions), and perhaps references to the applications used ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=,n)) ([Workato API - Recipes | Workato Docs](https://docs.workato.com/workato-api/recipes.html#:~:text=immediately.%20,4a99ae5d25ae%5C%22%7D%22%2C%20%22config%22%3A%22%5B%7B%5C%22keyword%5C%22%3A%5C%22application%5C%22%2C%5C%22name%5C%22%3A%5C%22clock%5C%22%2C%5C%22%20provider%5C%22%3A%5C%22clock%5C%22%7D%2C%7B%5C%22keyword%5C%22%3A%5C%22application%5C%22%2C%5C%22name%5C%22%3A%5C%22email%5C%22%2C%5C%22provider)). A connection JSON will include the connection name, the application (connector) it’s for (e.g. Salesforce, HTTP, etc.), but *no* credentials (as noted, sensitive fields are excluded) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=For%20security%20reasons%2C%20exporting%20a,placeholder%20is%20required%20after%20import)). A lookup table JSON contains the table name, column definitions, and possibly the row data if you chose to include data. Custom connector JSON would include the connector’s code or definition needed to reconstruct it. There may also be metadata files or manifest info, but primarily it’s one JSON per asset. Workato packages also support including **tags** (labels) for assets if you choose, so those can carry over between environments ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=3)).

**Versioning and source control:** One reason to export recipes is to store them in a version control system like Git ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=,version%20control%20systems%20like%20git)). Since the package is a set of JSON code files, you can commit them to a Git repository. Workato’s documentation suggests mapping each Workato project (which could correspond to a business project or integration) to a separate repository ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=Workato%20packages%20can%20be%20mapped,is%20bundled%20using%20a%20package)). For example, you might have a “Loan Processing Integration” project in Workato whose recipes are exported and stored in a `loan-integration` Git repo. Each time changes are made and exported, they can be committed, allowing you to track differences over time. It’s worth noting that Workato itself keeps version history of recipes in the UI, but having the JSON in Git provides a single history across environments and an external backup ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=securely%20in%20the%20git%20repository)). **Best practice:** Workato recommends using source control primarily for backup and collaboration, but **avoids editing the JSON files by hand** outside of Workato ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=However%2C%20it%20isn%E2%80%99t%20recommended%20that,version%20history%20visible%20in%20Workato)). This is because manual edits could bypass validations and would not appear in Workato’s own change logs. Instead, changes should be done in Workato, then exported out to Git as a record of that change.

When you export a package, you can optionally **specify versions** for each asset in the manifest (by default it uses the latest) ([Workato API - Recipe Lifecycle Management | Workato Docs](https://docs.workato.com/workato-api/recipe-lifecycle-management.html#:~:text=,false)). This means if you needed to export a previous version of a recipe (Workato does retain prior versions in its history), you could. However, in practice most exports use the current version of each recipe. The manifest itself can be saved and reused – if you add new recipes to a folder, you can edit the manifest to include them and export again, ensuring consistency of what’s being moved between environments ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=To%20export%20a%20package%2C%20you,initial%20creation%20and%20first%20export)).

### Importing Packages (Deployment)

Importing a package applies the packaged assets into a target Workato workspace (environment). You can import via the Workato UI (Tools > Recipe lifecycle management > Import) by uploading the zip, or programmatically via the Workato API (there are endpoints to import packages, which allows CI/CD servers to trigger deployments via scripts) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=,server%20using%20a%20cURL%20request)) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=,server%20using%20a%20cURL%20request)). When importing through the UI, you’ll select a **target folder** where the recipes will go, and then Workato will analyze the package and show a preview of changes.

**Import behavior and merge logic:** Each asset in the package is handled according to whether it already exists in the target environment. Workato assigns status tags like “**Creates new**”, “**Overwrites**”, or “No change” in the import preview ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=)). The general rules are:

- **Recipes:** If a recipe with the same name exists in the target folder, the import will **overwrite** it with the version from the package. If it doesn’t exist, it will create a new recipe ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Dependency%20type%20What%20Workato%20does,name%20exists%20in%20the%20folder)). This means you can safely re-import updates to an existing recipe and only that recipe’s definition will be updated (the recipe ID in the target might remain the same, preserving any references, but the logic inside updates).
- **Connections:** As discussed, an imported connection will not carry credentials. If a connection of the same name and type already exists in the environment, Workato does nothing (it assumes you have the proper connection set up) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=name%20already%20exists%20in%20the,App%20Connections)). If it doesn’t exist, Workato creates a **connection placeholder** that you must edit and authorize after import ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=For%20security%20reasons%2C%20exporting%20a,placeholder%20is%20required%20after%20import)) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=name%20already%20exists%20in%20the,App%20Connections)). This placeholder ensures the recipe imports correctly but won’t run until you provide credentials.
- **Custom connectors:** If a connector with the same name exists, it is overwritten (updated) with the package’s version; if not, a new custom connector is added ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Selected%20folder%20Custom%20connectors%20Overwrites,Lookup%20table)). This allows connector code updates to propagate.
- **Lookup tables:** If the table doesn’t exist, it will be created (with schema, and data if included). If it exists, the schema will be updated (e.g. new columns added if present). For the data, you choose to overwrite or not during import. “Overwrite” will replace all data in the table with the package’s data, while “Ignore” will leave the target table’s data as is ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=Lookup%20tables%20in%20the%20zip,be%20or%20overwritten%20or%20ignored)) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=%E2%80%98Overwrite%E2%80%99%20will%20cause%20all%20table,table%20was%20exported%20with%20data)). This choice is presented for each table in the UI (and can be controlled via API parameters if doing it programmatically).
- **Environment properties:** Workato allows defining **environment properties** (key-value pairs at the environment level, akin to global constants like configuration values). If your package includes environment properties, importing will **add any new properties** to the environment, but it will *not overwrite existing properties of the same name* ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=already%20exists,and%20displays%20an%20error)). This is intentional – environment properties often hold environment-specific values (like a base URL or email recipient for that environment). Workato assumes if the property name exists, you want to keep the current value. So, you might include a property “LOAN_API_URL” in the package. On import to prod, if “LOAN_API_URL” already exists in prod’s environment properties, it stays unchanged (likely pointing to prod API). If it didn’t exist, it gets created (and you would then set it to the prod URL).
- **Project properties:** These are similar to environment properties but scoped to a project (folder). They are imported into the specified project folder and also won’t overwrite existing ones of the same name ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=table%20data%20if%20selected%20during,Selected%20folder)). (Workato will error if you try to import project properties to the wrong scope like the All Projects root).
- **Other assets:** Workato also packages things like **recipe functions**, **common data models**, **message templates**, or **event streams** if used. The import behavior is analogous – e.g. a common data model (shared schema) will be added or updated in the target ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=project%20properties%20into%20the%20root,Event%20topics%20in%20the%20Workato)).

All these rules ensure that deploying a package doesn’t accidentally erase things it shouldn’t. You get a clear report of what will happen before confirming the import. Additionally, Workato enforces an **import buffer period** of 15 minutes between imports in the same environment ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=)) to avoid race conditions – something to keep in mind when scheduling automated deployments.

**Environment configuration practices:** It’s common to maintain separate Workato workspaces (or **Projects/Environments** in newer Workato parlance) for dev, test, prod. Packages facilitate promoting changes between them. To manage environment-specific configuration, the recommended practice is to externalize those values using environment or project properties (which, as noted, do not get overwritten on import) ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=already%20exists,and%20displays%20an%20error)). For example, a recipe might reference an environment property `LOAN_SYSTEM_BASE_URL` in its HTTP action. In dev, that property is set to the test server; in prod, it’s set to the live server. The recipe logic is identical in both environments (it just uses the property), and when you export/import the recipe, it carries a reference to `LOAN_SYSTEM_BASE_URL` but not the value. The value is already defined in each environment. This approach greatly simplifies deployments – you don’t have to tweak the recipe or worry about toggling endpoints; it automatically points to the correct URL after import ([Boost efficiency with environment and project properties | Workato Product Hub](https://www.workato.com/product-hub/boost-efficiency-with-environment-and-project-properties/#:~:text=scope%20of%20access%3A)) ([Boost efficiency with environment and project properties | Workato Product Hub](https://www.workato.com/product-hub/boost-efficiency-with-environment-and-project-properties/#:~:text=Environment%20property%3A%20The%20company,need%20to%20update%20the%20company)). The same applies for things like API keys or IDs that differ by environment: store them in properties or ensure each environment’s connection is configured appropriately. In short, **design recipes to be environment-agnostic**, with any environment-specific details coming from external properties or connections. This way, the exported package is truly portable.

### Export/Import Metadata and Versioning

Workato’s export manifest allows you to include metadata like tags and specific version numbers of assets. If you include **tags**, the package JSON for each asset will list any tags and these will be applied on import (you have a toggle for tags on export/import) ([Recipe lifecycle management - Exporting assets | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/export.html#:~:text=3)). Versioning in manifests (as mentioned) lets you capture a snapshot in time. Workato’s API also lets you retrieve details of an export manifest and even the contents of a package programmatically ([Workato API - Recipe Lifecycle Management | Workato Docs](https://docs.workato.com/workato-api/recipe-lifecycle-management.html#:~:text=optional%20Whether%20the%20asset%20is,Defaults%20to%20the%20root%20folder)) ([Workato API - Recipe Lifecycle Management | Workato Docs](https://docs.workato.com/workato-api/recipe-lifecycle-management.html#:~:text=curl%20%20,Copy%20of%20Recipeops)). Each package exported gets an ID; you can download the zip via API if needed ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=POST%20%2Fapi%2Fpackages%2Fexport%2F%3Amanifest_id%20Export%20package%20based,on%20a%20manifest)). For governance, you might track package versions (like “v1.2 of Loan Integration package”) either via Git tags or by naming conventions.

One thing to note: Workato packages are primarily meant for moving forward (dev → prod). There isn’t a built-in **roll-back** mechanism except re-importing an older package file. That’s where having version control in Git is useful – if a change causes issues, you can retrieve an earlier package (the JSON files from a previous commit) and re-import that to essentially roll back the recipes to a prior state. Always test packages in a lower environment before promoting to prod, to ensure all pieces (connections, properties, data) are aligned.

## CI/CD Pipeline for Workato (using GitHub Actions)

With the ability to export and import recipes as code, we can integrate Workato into Continuous Integration/Continuous Deployment (CI/CD) pipelines. Using **GitHub Actions** as an example, teams can automate the promotion of recipes and connectors across environments. Below, we explore how to set up a CI/CD pipeline for Workato, including the tools and best practices involved.

### Tools and Interfaces for Automation

- **Workato API:** Workato provides a REST API for managing assets and lifecycle operations. This includes endpoints to export packages (based on a manifest) and to import a package into a workspace ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=POST%20%2Fapi%2Fpackages%2Fexport%2F%3Amanifest_id%20Export%20package%20based,on%20a%20manifest)). It also includes endpoints to build/deploy projects for those using the Environments feature (with review and approval) ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=Type%20Resource%20Description%20POST%20%2Fapi%2Fprojects%2F%3Aid%2Fbuild,to%20build%20the%20project%20first)) ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=GET%20%2Fapi%2Fdeployments%2F%3Aid%2Feligible_reviewers%20%20Retrieves%20a,POST%20%2Fapi%2Fdeployments%2F%3Aid%2Fupdate_review_comment%20Updates%20a%20deployment)). In a CI/CD context, the API is typically used via script or HTTP calls (e.g. using `curl` or a platform-specific plugin) to trigger exports and imports as needed.
- **Workato CLI (Connector SDK):** For custom connectors, the Workato SDK gem provides a CLI that can be used in automation. For instance, you can run **RSpec tests** for your connector code as part of CI, and then use `workato push` to deploy an updated connector to a Workato workspace ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=,your%20Workato%20workspace)) ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=Run%20the%20workato%20push%20command%3A)). This CLI is Ruby-based, so you’d include steps in the GitHub Actions workflow to set up Ruby and the Workato gem.
- **GitHub Actions Secrets:** Since automation will require authenticating to Workato’s API or CLI, you should store credentials (like the Workato API token and API user email, or an API client ID/secret if using OAuth) in GitHub Secrets. For example, you might have `WORKATO_API_TOKEN` and `WORKATO_API_EMAIL` stored as repository or organization secrets. These can be referenced in the Actions YAML to securely provide credentials to the jobs ([Using secrets in GitHub Actions](https://docs.github.com/actions/security-guides/encrypted-secrets#:~:text=Using%20secrets%20in%20GitHub%20Actions,For)). Similarly, if your pipeline needs to supply any other sensitive data (like encryption keys for the Workato SDK or other service tokens), those should be in the secrets.

### Managing Source Control and Versioning

A typical approach is to treat the Workato **development environment** as the source of truth during active development, but use GitHub as the version control for changes:

1. **Development in Workato:** Builders create or modify recipes in a dev workspace (using Workato’s UI for recipe logic and testing with sample data).
2. **Export & Commit:** Once a set of changes is ready (say a feature or fix is completed), the recipes (and dependencies) are exported as a package. The JSON files from the package are then committed to a GitHub repository. This can be done manually by a developer (download the zip, unzip into the repo, commit) or automated by a script triggered via Workato’s API. Workato suggests using feature branches and pull requests to collaborate on these changes in Git ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=)) ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=Once%20the%20feature%20branch%20exists,PR%29%20for%20review)). For example, a developer might export the latest package, unzip it locally, and commit to a new branch representing the update. They then open a **Pull Request (PR)** on GitHub.
3. **Code Review:** On GitHub, team members can review the JSON changes. While they might not hand-edit the recipe JSON, the diff is useful to verify that only intended changes are present (and no accidental alterations). This is where having descriptive recipe names and perhaps comments in recipes helps – changes in the JSON can often be traced to specific step edits. Reviewers can leave comments, and if something needs adjustment, the developer goes back to Workato, makes changes, re-exports, and updates the branch ([Working with external source control systems | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/rdlc-guide-source-control.html#:~:text=)). Once approved, the PR is merged into the main branch.

At this point, the main branch of the repo has the latest package ready for deployment. This triggers the **CI/CD pipeline**.

### CI Pipeline (Continuous Integration)

For Workato, “CI” might involve validating that the exported assets are sound. Since Workato recipes are configuration (not code that can be compiled or unit-tested easily outside Workato), the CI part could be minimal. However, if you are using **custom connectors**, this is where you run their test suite. With GitHub Actions, you could set up a workflow that runs on pull request or push, which does something like:

- Checkout the repository.
- (If connectors present) Install Ruby and the Workato SDK, then run `bundle exec rspec` to execute any connector unit tests ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=,tests%20for%20your%20connector)) ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=,rb%3A16)). This ensures connector code changes don’t break expected behavior.
- Optionally, use Workato’s API in a dry-run manner – e.g., call the **Build** endpoint for a project without deploying, to see if Workato reports any errors in the package. (Workato’s Projects API can build a project and return a build ID, which you could theoretically use to validate that the package is importable).
- Linting or format checks on the JSON could also be done, but since it’s machine-generated, that’s usually unnecessary.

If the tests pass and the PR is merged, we proceed to deployment.

### CD Pipeline (Continuous Deployment)

Once the code is in the main branch (or a release branch), the CD process can kick in. Using GitHub Actions, you can have a workflow triggered on push to main or on a manual trigger that performs deployment steps. A typical deployment pipeline for Workato across environments might look like:

- **Deploy to Test/Staging:** The action uses the Workato API to import the package into the test environment. This might involve an HTTP POST to the `/api/packages/import/:folder_id` endpoint with the zip file. You can have the Action workflow first zip up the JSON files from the repo into a package. (Workato’s API expects a zip file payload when importing via the platform API ([Recipe lifecycle management - Importing | Workato Docs](https://docs.workato.com/recipe-development-lifecycle/import.html#:~:text=,server%20using%20a%20cURL%20request)).) The workflow can call `curl` with the appropriate headers (including the API token) to upload the package. Alternatively, Workato’s newer **Projects API** allows a one-step build-and-deploy: `/api/projects/:id/deploy` will take the latest project definition (which could have been pushed via Git or API) and deploy it ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=Type%20Resource%20Description%20POST%20%2Fapi%2Fprojects%2F%3Aid%2Fbuild,to%20build%20the%20project%20first)). But assuming a simple approach: the GitHub Action prepares the zip and calls the import API. After import, the recipes and other assets are now in the test workspace. The workflow can optionally then call the API to **start the recipes** (since imported recipes are typically off by default). For example, the API `PUT /api/recipes/:id/start` can be used to start each recipe ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=Type%20Resource%20Description%20GET%20%2Fapi%2Frecipes%2F%3Aid,DELETE%20%20135%20Delete%20recipe)). If you have many recipes, you might script a loop or have stored IDs.
- **Automated Testing in Test:** After deployment to a test environment, you could have automated integration tests. This could be as simple as triggering the recipes with sample events and verifying they ran successfully. Workato’s Monitoring API or job reports could be used to check for errors. Some teams skip this and do manual smoke tests in the test environment (since Workato is a bit opaque to automated testing beyond connector units).
- **Approval Gate:** Once testing is successful, you usually want a **manual approval** before pushing to production. There are a couple of ways to integrate approval:
  - **GitHub Actions environment protection:** GitHub Actions allows you to mark certain environments (like “production”) such that deployments require an approver to review and approve the job. You could configure the workflow so that deploying to prod is a separate job that requires approval. The pipeline might pause and wait for an authorized person to approve in the GitHub UI. Once approved, it continues to prod.
  - **Workato’s deployment review:** Workato’s platform itself supports an approval workflow in the context of their **Projects and Environments** feature. You can submit a deployment for review via API (`POST /api/deployments/:id/submit_for_review`) and then an authorized user can approve it (`POST /api/deployments/:id/approve`) before a final deploy call ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=GET%20%2Fapi%2Fdeployments%20%20Retrieves%20a,122%20Rejects%20a%20deployment)) ([Workato API - Resources | Workato Docs](https://docs.workato.com/workato-api/resources.html#:~:text=POST%20%2Fapi%2Fdeployments%2F%3Aid%2Freopen%20%20Re,api%2Fdeployments%2F%3Aid%2Fdeploy%20Deploys%20an%20approved%20deployment)). This is more commonly used in Workato’s Embedded Lifecycle or the CI/CD Accelerator, but it’s an option if you want to integrate Workato’s own gating. In a custom GitHub Actions pipeline, however, it’s usually simpler to use GitHub’s approval or an external change management approval.
- **Deploy to Production:** After approval, the pipeline will perform the same import process on the production Workato workspace. It will likely import the same zip package (perhaps from an artifact or by regenerating from the repo to ensure no drift). Connections in prod are already set up with prod credentials, environment properties with prod values are in place – so ideally the import is smooth with no manual steps. The recipes come in, connections map to existing ones, and everything is configured. The Action can then start the recipes in prod via API calls.

Throughout these stages, logging and notifications are important. The pipeline can be configured to send Slack messages or emails on success/failure using either GitHub Actions features or even Workato itself (Workato can integrate with GitHub webhooks to trigger recipes for notifications, but that’s an advanced usage).

To visualize, here is a simplified table of typical CI/CD stages for Workato with GitHub:

| **Stage**             | **Description**                                         | **Tools/Steps**                                                    |
|-----------------------|---------------------------------------------------------|---------------------------------------------------------------------|
| Develop & Export      | Build and test recipes in Workato dev workspace; export package of updated assets. | Workato UI (recipe editing & testing); RLCM export (manual or via API). |
| Version Control (CI)  | Commit the exported JSON files to Git; open PR for review. Changes are reviewed and merged to main. | GitHub (repo for JSON code, PR reviews). Possibly use GitHub Actions to run connector tests on PR. |
| Deploy to Staging/Test| Import the package into a staging environment for further testing. | GitHub Actions job – calls Workato API to import package. Then start recipes. (Could be automated on merge to main.) |
| Testing & Validation  | Run tests in staging – either manual QA or automated integration tests. Ensure the recipes function as expected with test data. | Workato environment (staging) – run sample jobs. (Optional: Workato monitoring APIs to verify job success). |
| Approval              | Get sign-off to release to production.                  | Manual approval in CI pipeline (GitHub Actions protected environment) or Workato deployment approval via API. |
| Deploy to Production  | Import the package into prod workspace; activate recipes. | GitHub Actions – upon approval, call Workato API to import to prod. Possibly use separate API token tied to prod account. Start recipes after import. |
| Post-Deployment       | Monitor production recipes for errors; notify team of success or handle rollbacks if issues. | Workato job reports/alerts (can be configured in Workato) or use a Workato recipe to send notifications. |

Each stage can be implemented with GitHub Actions steps. For example, using the **Workato API** in Actions might look like a step executing a `curl` command with the zip file. Secrets for API token ensure security. It’s also wise to use separate API tokens for different environments (one with access to dev/test, another for prod) to enforce access controls.

### Managing Secrets and Configurations in CI/CD

When the pipeline runs, it needs to handle sensitive data carefully:

- **Workato API credentials:** Use GitHub Secrets to store API tokens/emails. Never hard-code these in the repository. In the Actions YAML, reference them like `${{ secrets.WORKATO_TOKEN }}`.
- **Environment-specific IDs:** The pipeline might need to know, for instance, the folder ID where to import in staging or prod. You can either store those as well (e.g. a variable for `STAGING_FOLDER_ID`) or use the Workato API to look up by name (additional API call to list folders by name).
- **Preventing accidental prod runs:** Using GitHub environments and approvals as mentioned helps ensure that code merged doesn’t automatically deploy to prod without human oversight.
- **Rollback strategy:** If a deployment fails or a bug is found, you can revert by re-importing the last known good package. This is done by checking out the previous commit in Git (or a tagged release) and running the import steps again. Having a history of packages in Git (or as GitHub release artifacts) is useful for this reason.

### Example: Workato CLI in CI

If your integration heavily uses custom connectors, the CI pipeline could incorporate the Workato CLI more directly. For instance, you could have a connector project in its own repo. GitHub Actions can run on pushes to that repo, executing `workato push` (with the dev workspace API token) to update the connector in a dev/test environment for immediate testing ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=,your%20Workato%20workspace)) ([SDK - CLI - Getting started | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/getting-started.html#:~:text=Run%20the%20workato%20push%20command%3A)). After merging changes, another push could update the connector in prod. This is an example of using CI to manage just the connector portion. Recipes still would be exported/imported as above.

Workato’s own docs provide an example GitHub Actions workflow for connectors, focusing on running tests on each pull request ([SDK - Enabling CI/CD on GitHub | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/rspec/enable-ci-cd-on-github.html#:~:text=Next%2C%20you%27ll%20create%20a%20GitHub,steps%20the%20action%20will%20execute)) ([SDK - Enabling CI/CD on GitHub | Workato Docs](https://docs.workato.com/developing-connectors/sdk/cli/guides/rspec/enable-ci-cd-on-github.html#:~:text=steps%3A%20,needed%20if%20using%20encrypted%20files)). Adapting that, you ensure the connector is stable before it gets packaged with recipes.

### Tying It All Together with Approval Workflows

In a fully automated setup, you might combine Workato and GitHub capabilities. For instance, you could have Workato’s **Workbot** (a chatbot) notify Slack that a deployment is ready for approval, and on approval in Slack, call a webhook that triggers the GitHub Action to proceed to prod. Alternatively, simply use GitHub’s UI for approvals.

Workato’s **CI/CD Automation Accelerator** (a solution offered by Workato) essentially implements many of these steps out-of-the-box, using Workato recipes to orchestrate deployments via the RLCM APIs ([CI/CD Automation | Workato](https://www.workato.com/accelerators/ci_cd#:~:text=Continuous%20Integration%20and%20Continuous%20Delivery,by%20providing%20traceability%20across%20environments)) ([CI/CD Automation | Workato](https://www.workato.com/accelerators/ci_cd#:~:text=,project%20folders%20in%20any%20environment)). It supports multiple environments, pipelines, and even integrates with quality checks and Jira for change tracking ([CI/CD Automation | Workato](https://www.workato.com/accelerators/ci_cd#:~:text=Features%20include%3A)) ([CI/CD Automation | Workato](https://www.workato.com/accelerators/ci_cd#:~:text=%2A%20User%20Management%20for%20Role,the%20accelerator%20to%20maintain%20auditability)). While that is a more packaged approach, understanding the underlying process as we detailed gives you flexibility to tailor your own pipeline.

In summary, CI/CD for Workato involves treating your integration assets as code: export them, version them, test them, and promote them through environments in a controlled, automated way. By leveraging Workato’s export/import APIs and GitHub Actions for automation, teams can achieve rapid and reliable deployments of integration workflows – even those involving something as traditionally manual as Excel data and a legacy loan system. The result is that business automation can be managed with the same rigor and agility as application code, with clear traceability across environments ([CI/CD Automation | Workato](https://www.workato.com/accelerators/ci_cd#:~:text=Continuous%20Integration%20and%20Continuous%20Delivery,by%20providing%20traceability%20across%20environments)). 

